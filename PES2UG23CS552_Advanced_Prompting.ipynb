{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Shravani Isukapalli\n",
        "PES2UG23CS552"
      ],
      "metadata": {
        "id": "rG6as1mkgfQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python-dotenv --upgrade --quiet langchain langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5dbEtgCXTbw",
        "outputId": "0b6ba337-f226-4a90-c817-1e26136d93ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/111.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/111.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/500.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m500.5/500.5 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/158.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
        "\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buoNuJ9ZXV7P",
        "outputId": "7ab21273-c7bc-4e3b-ed74-aa2d9fdd3e54"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Groq API Key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"A student buys 4 notebooks for $8 each. He gets a discount of $6. What is the final amount he pays?\"\n",
        "prompt_standard = f\"Answer this question: {question}\"\n",
        "print(\"--- STANDARD (Llama3.1-8b) ---\")\n",
        "print(llm.invoke(prompt_standard).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x36RVi7CY34_",
        "outputId": "7c833dc2-54f2-421c-e428-5a79b19fa9d5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- STANDARD (Llama3.1-8b) ---\n",
            "To find the final amount the student pays, we need to calculate the total cost of the notebooks and then subtract the discount.\n",
            "\n",
            "The total cost of the notebooks is:\n",
            "4 notebooks * $8 each = $32\n",
            "\n",
            "The student gets a discount of $6, so we subtract this from the total cost:\n",
            "$32 - $6 = $26\n",
            "\n",
            "The final amount the student pays is $26.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt_cot = f\"Answer this question. Let's think step by step. {question}\"\n",
        "\n",
        "print(\"--- Chain of Thought (Llama3.1-8b) ---\")\n",
        "print(llm.invoke(prompt_cot).content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlbdUwksZIBQ",
        "outputId": "60b90498-ad6c-4e5a-e822-4435d70dc0b8"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Chain of Thought (Llama3.1-8b) ---\n",
            "To find the final amount the student pays, we need to follow these steps:\n",
            "\n",
            "1. Calculate the total cost of the notebooks before the discount:\n",
            "   Number of notebooks = 4\n",
            "   Cost per notebook = $8\n",
            "   Total cost = Number of notebooks * Cost per notebook\n",
            "   Total cost = 4 * $8\n",
            "   Total cost = $32\n",
            "\n",
            "2. Apply the discount:\n",
            "   Discount = $6\n",
            "   Final amount = Total cost - Discount\n",
            "   Final amount = $32 - $6\n",
            "   Final amount = $26\n",
            "\n",
            "So, the final amount the student pays is $26.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TOT and GOT"
      ],
      "metadata": {
        "id": "zzoiYltLZTVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install python-dotenv --upgrade --quiet langchain langchain-groq\n"
      ],
      "metadata": {
        "id": "Sc8jAx1EZPbV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "import getpass\n",
        "import os\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "if \"GROQ_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GROQ_API_KEY\"] = getpass.getpass(\"Enter your Groq API Key: \")\n",
        "\n",
        "# Using Llama3.1-8b\n",
        "llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0.7) # Creativity needed"
      ],
      "metadata": {
        "id": "R75fJSRtZYXD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnableParallel, RunnableLambda\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "problem = \"How can an engineering student improve productivity while preparing for exams?\"\n",
        "\n",
        "prompt_branch = ChatPromptTemplate.from_template(\n",
        "    \"Problem: {problem}. Give one unique and practical solution. Solution {id}:\"\n",
        ")\n",
        "\n",
        "branches = RunnableParallel(\n",
        "    sol1=prompt_branch.partial(id=\"1\") | llm | StrOutputParser(),\n",
        "    sol2=prompt_branch.partial(id=\"2\") | llm | StrOutputParser(),\n",
        "    sol3=prompt_branch.partial(id=\"3\") | llm | StrOutputParser(),\n",
        ")\n",
        "\n",
        "prompt_judge = ChatPromptTemplate.from_template(\n",
        "\"\"\"\n",
        "I have three proposed solutions for the problem: \"{problem}\"\n",
        "\n",
        "Solution 1:\n",
        "{sol1}\n",
        "\n",
        "Solution 2:\n",
        "{sol2}\n",
        "\n",
        "Solution 3:\n",
        "{sol3}\n",
        "\n",
        "Act as an Academic Productivity Expert. Select the most effective and sustainable solution for long-term productivity and explain why.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "tot_chain = (\n",
        "    RunnableParallel(problem=RunnableLambda(lambda x: x), branches=branches)\n",
        "    | (lambda x: {**x[\"branches\"], \"problem\": x[\"problem\"]})\n",
        "    | prompt_judge\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"--- Tree of Thoughts (ToT) Result ---\")\n",
        "print(tot_chain.invoke(problem))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_1cIBb-ZmSU",
        "outputId": "23fd3e25-747c-4742-e456-b64e76445c18"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Tree of Thoughts (ToT) Result ---\n",
            "After reviewing the three proposed solutions, I recommend **Solution 1: Implement the \"Pomodoro Technique with a Twist\"** as the most effective and sustainable solution for long-term productivity. Here's why:\n",
            "\n",
            "1. **Combination of techniques**: This solution combines the traditional Pomodoro Technique with active recall, spaced repetition, and the Stoplight System. This combination provides a comprehensive approach to learning and retention, making it more effective than relying on a single technique.\n",
            "2. **Personalization**: The Stoplight System allows students to categorize their study material based on their needs, making it a flexible and adaptable solution. This system helps students identify areas where they need to focus their efforts, ensuring that they prioritize their time and energy effectively.\n",
            "3. **Motivation and engagement**: The use of a \"twist\" on the traditional Pomodoro Technique makes it more engaging and motivating for students. The active recall and spaced repetition components provide opportunities for students to interact with the material in a meaningful way, reducing the likelihood of burnout and increasing motivation.\n",
            "4. **Long-term retention**: The combination of active recall, spaced repetition, and the Stoplight System helps students develop long-term retention of the material. This approach ensures that students don't just memorize information for the short-term but also understand and apply it in the long-term.\n",
            "5. **Flexibility and adaptability**: This solution can be adapted to fit different learning styles and needs. Students can adjust the duration of their Pomodoro sessions, the frequency of their breaks, and the level of difficulty of the material to suit their individual needs.\n",
            "\n",
            "In contrast, while Solutions 2 and 3 are effective, they have some limitations. Solution 2, the \"Pomodoro Calendar\" Technique, is more focused on organization and scheduling, which is essential but not sufficient for long-term productivity. Solution 3, \"Pomodoro Timer with Active Learning,\" is a good starting point but lacks the comprehensive approach and personalization of Solution 1.\n",
            "\n",
            "To implement Solution 1 effectively, I recommend the following:\n",
            "\n",
            "1. **Start with a clear goal**: Identify the specific topics or subjects you want to focus on and set achievable goals for each Pomodoro session.\n",
            "2. **Use a timer and a calendar**: Set a timer for 25 minutes and use a calendar to schedule your Pomodoro sessions and breaks.\n",
            "3. **Implement the Stoplight System**: Categorize your study material based on your needs, using the Stoplight System to identify must-know, key, and familiar concepts.\n",
            "4. **Practice active recall and spaced repetition**: Engage with the material by creating flashcards, summarizing key points, making concept maps, or practicing problems.\n",
            "5. **Review and adjust**: Regularly review your progress, adjust your approach as needed, and plan your next set of Pomodoros.\n",
            "\n",
            "By following these steps and implementing Solution 1, students can develop a sustainable and effective approach to productivity and learning that will serve them well throughout their academic careers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "prompt_draft = ChatPromptTemplate.from_template(\n",
        "    \"Write a 1-sentence idea about {topic} from the perspective of {perspective}.\"\n",
        ")\n",
        "\n",
        "drafts = RunnableParallel(\n",
        "    draft_ai=prompt_draft.partial(perspective=\"Artificial Intelligence\") | llm | StrOutputParser(),\n",
        "    draft_iot=prompt_draft.partial(perspective=\"Internet of Things\") | llm | StrOutputParser(),\n",
        "    draft_cloud=prompt_draft.partial(perspective=\"Cloud Computing\") | llm | StrOutputParser(),\n",
        ")\n",
        "\n",
        "prompt_combine = ChatPromptTemplate.from_template(\n",
        "\"\"\"\n",
        "I have three ideas about \"{topic}\":\n",
        "\n",
        "1. Artificial Intelligence: {draft_ai}\n",
        "\n",
        "2. Internet of Things: {draft_iot}\n",
        "\n",
        "3. Cloud Computing: {draft_cloud}\n",
        "\n",
        "Combine these ideas into one unified system. Explain how all three technologies work together to create an intelligent and efficient solution.\n",
        "Write one paragraph.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "got_chain = (\n",
        "    RunnableParallel(topic=RunnableLambda(lambda x: x), drafts=drafts)\n",
        "    | (lambda x: {**x[\"drafts\"], \"topic\": x[\"topic\"]})\n",
        "    | prompt_combine\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(\"--- Graph of Thoughts (GoT) Result ---\")\n",
        "print(got_chain.invoke(\"Smart Cities\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dd_PMk93ZzYO",
        "outputId": "e2114b46-9b45-4843-9afd-a3c4e51a5f36"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Graph of Thoughts (GoT) Result ---\n",
            "In a unified Smart City system, Artificial Intelligence (AI) serves as the strategic decision-maker, leveraging the vast amounts of data generated by the Internet of Things (IoT) to optimize urban systems. This data is collected and analyzed through a Cloud Computing platform, which provides real-time insights and efficient resource allocation. The AI then uses these insights to make data-driven decisions, streamlining transportation, waste management, and public services while maximizing energy efficiency. Additionally, the AI-driven platform enables seamless citizen engagement, providing personalized services, and enhancing overall quality of life through the IoT's ubiquitous sensing capabilities. By integrating these technologies, the Smart City becomes a harmonious blend of human experience and technological innovation, where residents, businesses, and infrastructure thrive in a connected, efficient, and sustainable ecosystem.\n"
          ]
        }
      ]
    }
  ]
}